{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e15c890",
   "metadata": {},
   "source": [
    "##  This is a webscrapper built to address the imbalanced dataset problem\n",
    "\n",
    "###  This scrapes the data from the website livemint.com "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "413658a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from googlesearch import search\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3af9b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_livemint_urls_from_google(query,results_to_return):\n",
    "    \"\"\"\n",
    "    Perform a Google search with a specified query on the 'livemint.com' website and return a list of URLs.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query to use, including site restriction, e.g., \"US economy site:livemint.com\".\n",
    "        results_to_return (int): The number of search results to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of URLs corresponding to the top search results on 'livemint.com'.\n",
    "    \"\"\" \n",
    "        \n",
    "        \n",
    "#     query = \"US economy site: livemint.com\"\n",
    "    search_results = search(query, num_results=results_to_return)\n",
    "    search_results = list(search_results)\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c245de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapping_the_mint(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "# Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#     # Find and remove unwanted 'p' elements (ads)\n",
    "    try:\n",
    "        unwanted_p_elements = soup.find(name=['p','strong'],string='You might also like')\n",
    "        for element in unwanted_p_elements:\n",
    "            element.extract()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        for a_tag in soup.find_all('a'):\n",
    "            a_tag.extract()\n",
    "    #     Find and extract relevant news articles\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "\n",
    "    articles = soup.find('div', class_='contentSec')  # Adjust the class name to match the HTML structure\n",
    "    # print(articles)\n",
    "\n",
    "    if articles:\n",
    "    #     Extract and print the content\n",
    "        article_content = articles.get_text()\n",
    "    #     print(article_content)\n",
    "    \n",
    "    try:\n",
    "        if article_content.find(\"Read more:\") != -1:\n",
    "            return article_content[0:article_content.find(\"Read more:\")]\n",
    "        \n",
    "        if article_content.find(\"Related Premium Stories\")!= -1:\n",
    "            return article_content[0:(article_content.find(\"Related Premium Stories\")-400)]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b4e267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minor_preprocessing(article_content):\n",
    "    \n",
    "#     print(type(article_content))    \n",
    "    try:\n",
    "        \n",
    "        article_content = article_content.strip()\n",
    "        article_content = article_content.replace(\"\\n\",\"\")\n",
    "        article_content = article_content.replace(\"    \",\"\")\n",
    "        article_content = article_content.replace(\"\\xa0\",\" \")\n",
    "    except:\n",
    "        pass\n",
    "    return article_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52e2546",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = get_livemint_urls_from_google(\"US economy site: livemint.com\",300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e1d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_economic_news = pd.DataFrame()\n",
    "# df_us_economic_news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0b42dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress   0.0%\n",
      "Progress   0.33%\n",
      "Progress   0.66%\n",
      "Progress   0.99%\n",
      "Progress   1.32%\n",
      "Progress   1.66%\n",
      "Progress   1.99%\n",
      "Progress   2.32%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [44], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m percent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(percent,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProgress   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpercent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m article_content \u001b[38;5;241m=\u001b[39m scrapping_the_mint(search_results[i])\n\u001b[1;32m      7\u001b[0m article_content \u001b[38;5;241m=\u001b[39m minor_preprocessing(article_content)\n\u001b[1;32m      8\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(article_content)\n",
      "Cell \u001b[0;32mIn [15], line 5\u001b[0m, in \u001b[0;36mscrapping_the_mint\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      2\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Parse the HTML content of the page\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m         soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     # Find and remove unwanted 'p' elements (ads)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bs4/__init__.py:333\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bs4/__init__.py:451\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bs4/builder/_htmlparser.py:399\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    397\u001b[0m parser\u001b[38;5;241m.\u001b[39msoup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m     parser\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTMLParseError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/html/parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03mas you want (may include '\\n').\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m+\u001b[39m data\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoahead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/html/parser.py:172\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    170\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_starttag(i)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[0;32m--> 172\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_endtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<!--\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[1;32m    174\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_comment(i)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/html/parser.py:420\u001b[0m, in \u001b[0;36mHTMLParser.parse_endtag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_data(rawdata[i:gtpos])\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m gtpos\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_endtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_cdata_mode()\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gtpos\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bs4/builder/_htmlparser.py:193\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_endtag\u001b[0;34m(self, name, check_already_closed)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malready_closed_empty_element\u001b[38;5;241m.\u001b[39mremove(name)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_endtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bs4/__init__.py:743\u001b[0m, in \u001b[0;36mBeautifulSoup.handle_endtag\u001b[0;34m(self, name, nsprefix)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;66;03m#print(\"End tag: \" + name)\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n\u001b[0;32m--> 743\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popToTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsprefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bs4/__init__.py:683\u001b[0m, in \u001b[0;36mBeautifulSoup._popToTag\u001b[0;34m(self, name, nsprefix, inclusivePop)\u001b[0m\n\u001b[1;32m    681\u001b[0m stack_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtagStack)\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(stack_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 683\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_tag_counter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    685\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtagStack[i]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = {\"text\":[]}\n",
    "for i in range(len(search_results)):\n",
    "    percent = i/len(search_results)*100\n",
    "    percent = round(percent,2)\n",
    "    print(f\"Progress   {percent}%\")\n",
    "    article_content = scrapping_the_mint(search_results[i])\n",
    "    article_content = minor_preprocessing(article_content)\n",
    "    data['text'].append(article_content)\n",
    "#     data += {'text':article_content,\n",
    "#        'relevance':'yes'}\n",
    "#     df_us_economic_news.append(data,ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "181d3dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2507/30750174.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_us_economic_news=df_us_economic_news.append(data['text'],ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_us_economic_news=df_us_economic_news.append(data['text'],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d256a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JPMorgan Chase CEO Jamie Dimon warned against ...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The US economy expanded at a 2.1 per cent annu...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An increasing number of economists — including...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The US economy accelerated to a 2.4% annual gr...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rising hopes of a soft landing for the US econ...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Last year, most US investors and central banke...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>The US economy grew at a 2.3% rate in the thir...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Federal Reserve policymakers are about to exte...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Washington: The US economy shrank less than ex...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>The US economy is likely to slow in 2022 and 2...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text relevance\n",
       "0    JPMorgan Chase CEO Jamie Dimon warned against ...       yes\n",
       "1    The US economy expanded at a 2.1 per cent annu...       yes\n",
       "2    An increasing number of economists — including...       yes\n",
       "3    The US economy accelerated to a 2.4% annual gr...       yes\n",
       "5    Rising hopes of a soft landing for the US econ...       yes\n",
       "..                                                 ...       ...\n",
       "148  Last year, most US investors and central banke...       yes\n",
       "150  The US economy grew at a 2.3% rate in the thir...       yes\n",
       "151  Federal Reserve policymakers are about to exte...       yes\n",
       "154  Washington: The US economy shrank less than ex...       yes\n",
       "156  The US economy is likely to slow in 2022 and 2...       yes\n",
       "\n",
       "[108 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save dataset\n",
    "temp = {df_us_economic_news.columns[0]:'text'}\n",
    "df_us_economic_news=df_us_economic_news.rename(columns=temp)\n",
    "df_us_economic_news['relevance'] = \"yes\"\n",
    "df_us_economic_news.dropna(inplace=True)\n",
    "df_us_economic_news.to_csv(\"us_economy_df.csv\",header=True,index=False)\n",
    "df_us_economic_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c5e13ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Billionaire investor Warren Buffett on Saturday signaled he has lost none of his enduring confidence in the U.S. economy and his company Berkshire Hathaway Inc . In his annual letter to Berkshire shareholders, the 92-year-old Buffett urged investors to focus on the big picture over the long term, rather than higher inflation and other factors that in 2022 dampened stock prices, though not Berkshire\\'s.    Warren Buffet\\'s annual letter: Key highlights   Bet on Coca-ColaIn August 1994 – yes, 1994 – Berkshire completed its seven-year purchase of the 400 million shares of Coca-Cola we now own. The total cost was $1.3 billion – then a very meaningful sum at Berkshire.The cash dividend we received from Coke in 1994 was $75 million. By 2022, the dividend had increased to $704 million. Growth occurred every year, just as certain as birthdays. All Charlie and I were required to do was cash Coke’s quarterly dividend checks. We expect that those checks are highly likely to grow.  Dividends from American Express is much the same story. Berkshire’s purchases of Amex were essentially completed in 1995 and, coincidentally, also cost $1.3 billion. Annual dividends received from this  have grown from $41 million to $302 million. Those checks, too, seem highly likely to increase.These dividend gains, though pleasing, are far from spectacular. But they bring with them important gains in stock prices. At yearend, our Coke investment was valued at $25 billion while Amex was recorded at $22 billion. Each holding now accounts for roughly 5% of Berkshire’s  worth, akin to its weighting long ago.  “Efficient\" markets exist only in textbooks“Efficient\" markets exist only in textbooks. In truth, marketable stocks and bonds are baffling, their behavior usually understandable only in retrospect.In his annual letter to Berkshire shareholders, the 92-year-old Buffett urged investors to focus on the big picture over the long term, rather than higher inflation and other factors that in 2022 dampened , though not Berkshire\\'s.  On American EconomyWarren Buffet also urged Americans not to be convulsed by \"self-criticism and self-doubt,\" saying the country\\'s dynamism has benefited Berkshire in his 58 years running the company from Omaha, Nebraska, and will do so after he passes the reins.\"We count on the American Tailwind and, though it has been becalmed from time to time, its propelling force has a'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_economic_news['text'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e551748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_economic_news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a54e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
